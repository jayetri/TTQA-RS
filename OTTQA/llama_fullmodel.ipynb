{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f65186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "028281c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--option\", default=\"none\", type=str)\n",
    "parser.add_argument(\"--model\", default=\"llama2-70b\", type=str, help=\" ")\n",
    "parser.add_argument(\"--start\", default=0, type=int)\n",
    "parser.add_argument(\"--end\", default=None, type=int)\n",
    "parser.add_argument(\n",
    "    \"--temperature\",\n",
    "    type=float,\n",
    "    default=0.5,\n",
    "    help=\"temperature of 0 implies greedy sampling.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--traced_json_file\",\n",
    "    default=r\"traced.json\",#traced file\n",
    "    type=str,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--tables_json_file\",\n",
    "    default=r\"tables.json\",#table files\n",
    "    type=str,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--topk_path\",\n",
    "    default=r\"request_tok\",#text files\n",
    "    \n",
    "    type=str,\n",
    ")\n",
    "\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e279553",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_data(args):\n",
    "    data_train_traced = json.load(open(args.traced_json_file, \"r\"))\n",
    "    traindev_table = json.load(open(args.tables_json_file, \"r\"))\n",
    "\n",
    "    data_list = []\n",
    "    for sample in tqdm(data_train_traced[args.start:args.end]):\n",
    "        table_id = sample[\"table_id\"]\n",
    "        try:\n",
    "            topk = json.load(open(os.path.join(args.topk_path, f\"{table_id}.json\"), \"r\"))\n",
    "        except Exception:\n",
    "            print(f\"The file {os.path.join(args.topk_path, f'{table_id}.json')} does not exist.\")\n",
    "            continue\n",
    "        question_text = sample[\"question\"]\n",
    "        answer_text = sample[\"answer-text\"]\n",
    "        wikis = [\n",
    "            node[2]\n",
    "            for node in sample[\"answer-node\"]\n",
    "            if node[2] is not None and node[2].startswith(\"/wiki\")\n",
    "        ]\n",
    "        if len(wikis) == 0:\n",
    "            wiki_text = \"\"\n",
    "        else:\n",
    "            wiki_text = \"\\n\".join([topk[wiki] for wiki in wikis])\n",
    "        df = pd.DataFrame(\n",
    "            [tuple(zip(*row))[0] for row in traindev_table[table_id][\"data\"]],\n",
    "            columns=list(zip(*traindev_table[table_id][\"header\"]))[0],\n",
    "        )\n",
    "        data_list.append(\n",
    "            {\n",
    "                \"question\": question_text,\n",
    "                \"answer\": answer_text,\n",
    "                \"title\": traindev_table[table_id][\"title\"],\n",
    "                \"table\": df,\n",
    "                \"wiki\": wiki_text,\n",
    "                \"table_id\": table_id,\n",
    "                \"intro\": traindev_table[table_id][\"intro\"]\n",
    "            }\n",
    "        )\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def df_format(data):\n",
    "    try:\n",
    "        formatted_str = \" | \".join(data.columns) + \"\\n\"\n",
    "        for _, row in data.iterrows():\n",
    "            row_str = \" | \".join([str(row[col]) for col in data.columns])\n",
    "            formatted_str += row_str + \"\\n\"\n",
    "        return formatted_str\n",
    "    except:\n",
    "        print(f\"wrong table: {csv_path}\")\n",
    "        return \"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b525f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstration = {}\n",
    "demonstration[\"none\"] = \"\"\n",
    "with open(\"examples/fullmodel_direct_3shot.json\", \"r\") as f:\n",
    "    demonstration[\"direct\"] = json.load(f)\n",
    "with open(\"examples/fullmodel_cot_3shot.json\", \"r\") as f:\n",
    "    demonstration[\"cot\"] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56254a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5229"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d_%H_%M\")\n",
    "fw = open(f\"outputs/subquestion_s{args.start}_e{args.end}_{args.option}_{args.model}_{dt_string}.json\", \"w\",)\n",
    "tmp = {\"demonstration\": demonstration[args.option]}\n",
    "fw.write(json.dumps(tmp) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a55fc01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▌                                                                          | 49/600 [00:00<00:08, 61.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file data\\traindev_request_tok\\Rachael_vs._Guy:_Celebrity_Cook-Off_2.json does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [00:06<00:00, 97.28it/s]\n"
     ]
    }
   ],
   "source": [
    "data_list = read_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e532ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model or API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f0af863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 599/599 [27:51<00:00,  2.79s/it]\n"
     ]
    }
   ],
   "source": [
    "with open('subquestion', 'r') as f: # generated subquestion with answer\n",
    "    subquestion_data = [json.loads(line) for line in f]\n",
    "    \n",
    "with open('entity', 'r', encoding='utf-8') as f: # generated entity\n",
    "    entity_data = [line.strip() for line in f]\n",
    "    \n",
    "with open('summary', 'r') as f: #generated summary\n",
    "    summary_data = [json.loads(line) for line in f]\n",
    "    \n",
    "# Iterate over data_list and evidence_data simultaneously\n",
    "for entry, subquestion_entry, entity_entry, summary_entry in zip(tqdm(data_list), subquestion_data, entity_data, summary_data):\n",
    "    question = entry['question']\n",
    "    answer = entry['answer']\n",
    "    table_id = entry['table_id']\n",
    "    subanswer = subquestion_entry.get('sub_answer', '')  # Use .get() to handle KeyError\n",
    "    subquestion = subquestion_entry.get('sub_question', '')\n",
    "    subquestion_table_id = subquestion_entry.get('table_id', '')  # Get evidence table_id\n",
    "    summary = summary_entry.get('summary', '')\n",
    "    \n",
    "\n",
    "    # Check if evidence table_id matches the entry table_id\n",
    "    if subquestion_table_id != table_id:\n",
    "        print(f\"Warning: Table ID mismatch for question '{question}'.\")\n",
    "        # Optionally, you can choose to skip this entry or handle it differently\n",
    "\n",
    "    #### Formalizing the k-shot demonstration. #####\n",
    "    prompt = demonstration[args.option] + '\\n\\n'\n",
    "    prompt += f'Read the following table and text regarding \"{entry[\"title\"]}\":'+'and answer the question.\\n\\n'\n",
    "    prompt += df_format(entry['table']) + '\\n'\n",
    "\n",
    "    if entry['wiki']:\n",
    "        prompt += \"Text: \" + '\\n' + entry['wiki'] + '\\n\\n'\n",
    "    prompt +=  \"Summary: \" + summary+ '\\n\\n'\n",
    "    # Add evidence to the prompt\n",
    "    prompt += \"Subquestion as hint: \" + subquestion + \"\\nThe answer of subquestion: \" + subanswer + '\\n\\n'\n",
    "    prompt += \"Using exactly the same word from the text and table as answer can achieve better correct rate. Simplify your answer to a/an: \"+entity_entry + '\\n\\n'\n",
    "    prompt += 'Lets think step by step, and answer the question: ' + question \n",
    "    prompt += '\\nAnswer:'\n",
    "    response_raw = query({'inputs': prompt})\n",
    "\n",
    "    try:\n",
    "        response = response_raw[0].get('generated_text', '').split('\\nAnswer:')[4].split('Reasoning process')[0].strip()\n",
    "    except KeyError:\n",
    "        response = ''\n",
    "\n",
    "    response = response.split('\\n')[0].strip()\n",
    "\n",
    "    tmp = {\n",
    "        \"question\": question,\n",
    "        \"response\": response,\n",
    "        \"answer\": answer,\n",
    "        \"entity\":entity_entry,\n",
    "        \"table_id\": entry[\"table_id\"],\n",
    "        \"sub_answer\": subanswer\n",
    "    }\n",
    "\n",
    "    fw.write(json.dumps(tmp) + \"\\n\")\n",
    "\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a571a7d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Read the following table and text regarding \"Nonso Anozie\":and answer the question.\n",
      "\n",
      "Year | Title | Role | Notes\n",
      "2007 | Prime Suspect 7 : The Final Act | Robert | Episode : Part 1\n",
      "2009 | Occupation | Erik Lester | 3 episodes\n",
      "2011 | Outcasts | Elijah | 1 episode\n",
      "2011 | Stolen | Thomas Ekoku | TV movie\n",
      "2012 | Game of Thrones | Xaro Xhoan Daxos | 5 episodes\n",
      "2013 | The Bible | Samson | Episode : Homeland\n",
      "2013 | Playhouse Presents | Chris | Episode : The Pavement Psychologist\n",
      "2013-14 | Dracula | R.M . Renfield | Main cast ; 10 episodes\n",
      "2015-17 | Zoo | Abraham Kenyatta | Main cast\n",
      "2015 | Tut | General Horemheb | Miniseries ; 3 episodes\n",
      "2015 | Doctor Who | Hydroflax ( body { voice only } ) | Episode : The Husbands of River Song\n",
      "2016 | A Midsummer Night 's Dream | Oberon | TV movie\n",
      "\n",
      "Text: \n",
      "Prime Suspect is a British police procedural television drama series devised by Lynda La Plante . It stars Helen Mirren as Jane Tennison , one of the first female Detective Chief Inspectors in Greater London 's Metropolitan Police Service , who rises to the rank of Detective Superintendent while confronting the institutionalised sexism that exists within the police force .\n",
      "\n",
      "Summary: \n",
      "\n",
      "Subquestion as hint: In which series did actor Nonso Anozie play the character of Robert?\n",
      "The answer of subquestion: Prime Suspect 7 : The Final Act\n",
      "\n",
      "Using exactly the same word from the text and table as answer can achieve better correct rate. Simplify your answer to an entity\n",
      "\n",
      "Lets think step by step, and answer the question: Who created the series in which the character of Robert , played by actor Nonso Anozie , appeared ?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6492c988-ee25-426d-b9a5-2a100f79009a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Read the following table and text regarding \"Nonso Anozie\":and answer the question.\n",
      "\n",
      "Year | Title | Role | Notes\n",
      "2007 | Prime Suspect 7 : The Final Act | Robert | Episode : Part 1\n",
      "2009 | Occupation | Erik Lester | 3 episodes\n",
      "2011 | Outcasts | Elijah | 1 episode\n",
      "2011 | Stolen | Thomas Ekoku | TV movie\n",
      "2012 | Game of Thrones | Xaro Xhoan Daxos | 5 episodes\n",
      "2013 | The Bible | Samson | Episode : Homeland\n",
      "2013 | Playhouse Presents | Chris | Episode : The Pavement Psychologist\n",
      "2013-14 | Dracula | R.M . Renfield | Main cast ; 10 episodes\n",
      "2015-17 | Zoo | Abraham Kenyatta | Main cast\n",
      "2015 | Tut | General Horemheb | Miniseries ; 3 episodes\n",
      "2015 | Doctor Who | Hydroflax ( body { voice only } ) | Episode : The Husbands of River Song\n",
      "2016 | A Midsummer Night 's Dream | Oberon | TV movie\n",
      "\n",
      "Text: \n",
      "Prime Suspect is a British police procedural television drama series devised by Lynda La Plante . It stars Helen Mirren as Jane Tennison , one of the first female Detective Chief Inspectors in Greater London 's Metropolitan Police Service , who rises to the rank of Detective Superintendent while confronting the institutionalised sexism that exists within the police force .\n",
      "\n",
      "Summary: \n",
      "\n",
      "Subquestion as hint: In which series did actor Nonso Anozie play the character of Robert?\n",
      "The answer of subquestion: Prime Suspect 7 : The Final Act\n",
      "\n",
      "Using exactly the same word from the text and table as answer can achieve better correct rate. Simplify your answer to an entity\n",
      "\n",
      "Lets think step by step, and answer the question: Who created the series in which the character of Robert , played by actor Nonso Anozie , appeared ?\n",
      "Answer: Lynda La Plante\n"
     ]
    }
   ],
   "source": [
    "print(response_raw[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456caddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 599/599 [21:59<00:00,  2.20s/it]\n"
     ]
    }
   ],
   "source": [
    "for entry in tqdm(data_list):\n",
    "    question = entry['question']\n",
    "    answer = entry['answer']\n",
    "\n",
    "    #### Formalizing the k-shot demonstration. #####\n",
    "    prompt = demonstration[args.option] + '\\n\\n'\n",
    "    prompt += f'Read the table and text regarding \"{entry[\"title\"]}\" and create a summary.\\n\\n'\n",
    "    #prompt += f\"This is the introduction of the table:\" + '\\n' + entry['intro'] + '\\n\\n'\n",
    "    prompt += df_format(entry['table']) + '\\n'\n",
    "    \n",
    "    if entry['wiki']:\n",
    "        prompt += \"Text\" + '\\n' + entry['wiki'] + '\\n\\n'\n",
    "\n",
    "    prompt += 'Summarize the given table and text. ' + '\\nSummary:'\n",
    "\n",
    "    response_raw = query({'inputs': prompt})\n",
    "    try:\n",
    "        response = response_raw[0].get('generated_text', '').split('\\nSummary:')[1].split('Reasoning process')[0].strip()\n",
    "    except KeyError:\n",
    "        response = ''\n",
    "\n",
    "    response = response.split('\\n')[0].strip()\n",
    "\n",
    "    tmp = {\n",
    "        \"question\": question,\n",
    "        \"summary\": response,\n",
    "        \"table_id\": entry[\"table_id\"],\n",
    "    }\n",
    "\n",
    "    fw.write(json.dumps(tmp) + \"\\n\")\n",
    "\n",
    "fw.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5f21225-f092-49f4-8b2b-a087131f0991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  5.98it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = \"outputs/summary\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for entry in tqdm(data_list):\n",
    "    question = entry['question']\n",
    "    answer = entry['answer']\n",
    "\n",
    "    #### Formalizing the k-shot demonstration. #####\n",
    "    prompt = demonstration[args.option] + '\\n\\n'\n",
    "    prompt += f'Read the table and text regarding \"{entry[\"title\"]}\" and create a summary.\\n\\n'\n",
    "    prompt += df_format(entry['table']) + '\\n'\n",
    "    \n",
    "    if entry['wiki']:\n",
    "        prompt += \"Text\" + '\\n' + entry['wiki'] + '\\n\\n'\n",
    "\n",
    "    prompt += 'Summarize the given table and text. ' + '\\nSummary:'\n",
    "\n",
    "    response_raw = query({'inputs': prompt})\n",
    "    try:\n",
    "        response = response_raw[0].get('generated_text', '').split('\\nSummary:')[1].split('Reasoning process')[0].strip()\n",
    "    except KeyError:\n",
    "        response = ''\n",
    "\n",
    "    response = response.split('\\n')[0].strip()\n",
    "\n",
    "    output_file_path = os.path.join(output_dir, f\"{entry['table_id']}.txt\")\n",
    "\n",
    "    with open(output_file_path, \"w\", encoding=\"utf-8\") as fw:\n",
    "        fw.write(f\"Prompt:\\n{prompt}\\n\\n\")\n",
    "        fw.write(f\"Summary: {response}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f65186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028281c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--option\", default=\"cot\", type=str)\n",
    "parser.add_argument(\"--model\", default=\"llama2-70b\", type=str, help=\" \")\n",
    "parser.add_argument(\"--start\", default=0, type=int)\n",
    "parser.add_argument(\"--end\", default=None, type=int)\n",
    "parser.add_argument(\n",
    "    \"--temperature\",\n",
    "    type=float,\n",
    "    default=0.5,\n",
    "    help=\"temperature of 0 implies greedy sampling.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--traced_json_file\",\n",
    "    default=r\"traced.json\",#traced file\n",
    "    type=str,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--tables_json_file\",\n",
    "    default=r\"tables.json\",#table files\n",
    "    type=str,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--topk_path\",\n",
    "    default=r\"request_tok\",#text files\n",
    "    \n",
    "    type=str,\n",
    ")\n",
    "\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e279553",
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstration = {}\n",
    "demonstration[\"none\"] = \"\"\n",
    "with open(\"examples/fullmodel_direct_3shot.json\", \"r\") as f:\n",
    "    demonstration[\"direct\"] = json.load(f)\n",
    "with open(\"examples/fullmodel_cot_3shot.json\", \"r\") as f:\n",
    "    demonstration[\"cot\"] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca55ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(args):\n",
    "    # Load traced JSON file\n",
    "    data_test_traced = json.load(open(args.traced_json_file, \"r\"))\n",
    "    data_list = []\n",
    "    for sample in tqdm(data_test_traced[args.start:args.end]):\n",
    "        table_id = sample[\"table_id\"]\n",
    "        question_data = None\n",
    "        for q_data in questions_data:\n",
    "            if q_data['table_id'] == table_id:\n",
    "                question_data = q_data\n",
    "                break\n",
    "        if question_data is None:\n",
    "            print(f\"No question data found for {table_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Read JSON file from tables_tok\n",
    "        try:\n",
    "            tables_tok_path = f\"{table_id}.json\"  # put your traced table link\n",
    "            with open(tables_tok_path, 'r') as f:\n",
    "                table_data = json.load(f)\n",
    "        except Exception:\n",
    "            print(f\"The file {table_id} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        question_type = question_data['type']\n",
    "        if question_type == 'bridge':\n",
    "            # Get the index of the most relevant row\n",
    "            row_index = question_data['row_pre']\n",
    "            relevant_rows = [table_data['data'][row_index]]\n",
    "        elif question_type == 'comparison':\n",
    "            # Get the indices of all rows with relevance less than or equal to 1.0\n",
    "            row_pre_logits = question_data['row_pre_logit']\n",
    "            relevant_rows = [table_data['data'][i] for i, logit in enumerate(row_pre_logits) if logit <= 1.0]\n",
    "        else:\n",
    "            print(f\"Unknown question type: {question_type}\")\n",
    "            continue\n",
    "\n",
    "        # Read text data\n",
    "        try:\n",
    "            text_file = os.path.join(args.text_path, f\"{table_id}.json\")\n",
    "            with open(text_file, \"r\") as f:\n",
    "                text_data = json.load(f)\n",
    "        except Exception:\n",
    "            print(f\"The file {text_file} does not exist.\")\n",
    "            continue\n",
    "            \n",
    "        question_text = sample[\"question\"]\n",
    "        answer_text = sample[\"pred\"]\n",
    "        \n",
    "        # Extract wiki links from nodes and target\n",
    "        wikis = [\n",
    "            node[2]\n",
    "            for node in sample[\"nodes\"]\n",
    "            if node[2] is not None and node[2].startswith(\"/wiki\")\n",
    "        ]\n",
    "        \n",
    "        target_wiki = sample[\"target\"][2]\n",
    "        if target_wiki and target_wiki.startswith(\"/wiki\"):\n",
    "            wikis.append(target_wiki)\n",
    "        \n",
    "        # Get the corresponding text for each wiki link\n",
    "        wiki_text = \"\"\n",
    "        if wikis:\n",
    "            wiki_lines = [text_data.get(wiki, \"\") for wiki in wikis]\n",
    "            wiki_text = \"\\n\".join(wiki_lines)\n",
    "        \n",
    "        # Create a DataFrame from the table data\n",
    "        df = pd.DataFrame(\n",
    "            [tuple(zip(*row))[0] for row in table_data[\"data\"]],\n",
    "            columns=list(zip(*table_data[\"header\"]))[0],\n",
    "        )\n",
    "\n",
    "        data_list.append({\n",
    "            \"table_id\": table_id,\n",
    "            \"question\": question_text,\n",
    "            \"answer\": answer_text,\n",
    "            \"table\": df,\n",
    "            \"wiki\": wiki_text,\n",
    "            \"title\": table_data[\"title\"],\n",
    "            \"intro\": table_data[\"intro\"]\n",
    "        })\n",
    "\n",
    "    return data_list\n",
    "\n",
    "# Load questions data\n",
    "questions_path = \"test.json\"  # put text answer here\n",
    "with open(questions_path, 'r') as f:\n",
    "    questions_data = json.load(f)\n",
    "\n",
    "def df_format(data):\n",
    "    try:\n",
    "        formatted_str = \" | \".join(data.columns) + \"\\n\"\n",
    "        for _, row in data.iterrows():\n",
    "            row_str = \" | \".join([str(row[col]) for col in data.columns])\n",
    "            formatted_str += row_str + \"\\n\"\n",
    "        return formatted_str\n",
    "    except Exception as e:\n",
    "        #print(f\"Error formatting table: {data}, error: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e532ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model or API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56254a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_count = 0\n",
    "\n",
    "subquestion_file = f\"outputs/subquestion_s{args.start}_e{args.end}_{args.option}_{args.model}_{run_count}.json\"\n",
    "subquestion_fw = open(subquestion_file, \"w\")\n",
    "\n",
    "tmp = {\"demonstration\": demonstration[args.option]}\n",
    "subquestion_fw.write(json.dumps(tmp) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55fc01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = read_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6dc51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('question_test.json', 'r') as f:\n",
    "    all_questions = []\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        all_questions.append(data['response'])\n",
    "\n",
    "with open('subquestion_spacy.txt', 'r', encoding='utf-8') as f:\n",
    "    entity_data = [line.strip() for line in f]\n",
    "\n",
    "question_idx = 0\n",
    "\n",
    "for entry, entity_entry in zip(tqdm(data_list), entity_data):\n",
    "    # Retrieve the current question from the list of questions\n",
    "    if question_idx < len(all_questions):\n",
    "        question = all_questions[question_idx]\n",
    "    else:\n",
    "        # Terminate the loop if the list of questions is exhausted\n",
    "        break\n",
    "    \n",
    "    prompt = demonstration[args.option] + '\\n\\n'\n",
    "    # Formalizing the k-shot demonstration.\n",
    "    prompt += f'Read the table and text regarding \"{entry[\"title\"]}\" to answer the question.\\n\\n'\n",
    "    prompt += df_format(entry['table']) + '\\n'\n",
    "\n",
    "    if entry['wiki']:\n",
    "        prompt += \"Text:\" + '\\n' + entry['wiki'] + '\\n\\n'\n",
    "    prompt += 'The answer should be a/an ' + entity_entry + '\\n\\n'\n",
    "    prompt += 'Let\\'s think step by step, to answer the question: ' + question + '\\nAnswer:'\n",
    "\n",
    "    # Process the question and answer...\n",
    "\n",
    "    # Update the question index\n",
    "    question_idx += 1\n",
    "    response_raw = query({'inputs': prompt})\n",
    "    try:\n",
    "        response = response_raw[0].get('generated_text', '').split('\\nAnswer:')[3].split('Reasoning process')[0].strip()\n",
    "    except KeyError:\n",
    "        response = ''\n",
    "\n",
    "    response = response.split('\\n')[0].strip()\n",
    "\n",
    "    tmp = {\n",
    "        \"sub_question\": question,\n",
    "        \"sub_answer\": response,\n",
    "        \"table_id\": entry[\"table_id\"],\n",
    "    }\n",
    "\n",
    "    subquestion_fw.write(json.dumps(tmp) + \"\\n\")\n",
    "\n",
    "subquestion_fw.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7397f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31048a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d556af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d_%H_%M\")\n",
    "answer_fw = open(f\"outputs/answer_s{args.start}_e{args.end}_{args.option}_{args.model}_{dt_string}.json\", \"w\",)\n",
    "tmp = {\"demonstration\": demonstration[args.option]}\n",
    "answer_fw.write(json.dumps(tmp) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c25f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = read_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da853735",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('outputs/subanswer.json', 'r') as f:  #subquestion answer here\n",
    "    next(f)  # Skip the first line\n",
    "    subquestion_data = [json.loads(line) for line in f]\n",
    "    \n",
    "with open('entity.txt', 'r', encoding='utf-8') as f:\n",
    "    entity_data = [line.strip() for line in f]\n",
    "    \n",
    "# Iterate over data_list and evidence_data simultaneously\n",
    "for entry, subquestion_entry, entity_entry in zip(tqdm(data_list), subquestion_data, entity_data):\n",
    "    question = entry['question']\n",
    "    answer = entry['answer']\n",
    "    table_id = entry['table_id']\n",
    "    subanswer = subquestion_entry.get('sub_answer', '')  # Use .get() to handle KeyError\n",
    "    subquestion = subquestion_entry.get('sub_question', '')\n",
    "    subquestion_table_id = subquestion_entry.get('table_id', '')  # Get evidence table_id\n",
    "    \n",
    "\n",
    "    # Check if evidence table_id matches the entry table_id\n",
    "    if subquestion_table_id != table_id:\n",
    "        print(f\"Warning: Table ID mismatch for question '{question}'.\")\n",
    "        # Optionally, you can choose to skip this entry or handle it differently\n",
    "\n",
    "    #### Formalizing the k-shot demonstration. #####\n",
    "    prompt = demonstration[args.option] + '\\n\\n'\n",
    "    prompt += f'Read the following table and text regarding \"{entry[\"title\"]}\":'+'and answer the question.\\n\\n'\n",
    "    prompt += df_format(entry['table']) + '\\n'\n",
    "\n",
    "    if entry['wiki']:\n",
    "        prompt += \"Text: \" + '\\n' + entry['wiki'] + '\\n\\n'\n",
    "        \n",
    "    # Add evidence to the prompt\n",
    "    prompt += \"Subquestion: \" + subquestion + \"\\nThe answer of subquestion: \" + subanswer + '\\n\\n'\n",
    "    prompt += \"Using exactly the same word from the text and table as answer can achieve better correct rate.\\n\"\n",
    "    prompt += \"Simplify your answer to a/an :\" + entity_entry\n",
    "    prompt += 'Lets think step by step and answer question: ' + question \n",
    "    prompt += '\\nAnswer:'\n",
    "    response_raw = query({'inputs': prompt})\n",
    "\n",
    "    try:\n",
    "        response = response_raw[0].get('generated_text', '').split('\\nAnswer:')[4].split('Reasoning process')[0].strip()\n",
    "    except KeyError:\n",
    "        response = ''\n",
    "\n",
    "    response = response.split('\\n')[0].strip()\n",
    "\n",
    "    tmp = {\n",
    "        \"question\": question,\n",
    "        \"response\": response,\n",
    "        \"answer\": answer,\n",
    "        \"entity\":entity_entry,\n",
    "        \"table_id\": entry[\"table_id\"],\n",
    "        \"sub_answer\": subanswer\n",
    "    }\n",
    "\n",
    "    answer_fw.write(json.dumps(tmp) + \"\\n\")\n",
    "\n",
    "answer_fw.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a571a7d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68299cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_raw[0]['generated_text'].split('\\nAnswer:')[1].split('\\n')[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6492c988-ee25-426d-b9a5-2a100f79009a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(response_raw[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f21225-f092-49f4-8b2b-a087131f0991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

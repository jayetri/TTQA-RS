{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f45dbd-59a2-4638-a881-215386aae9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Set paths\n",
    "BASE_PATH = \"HybridQA\"\n",
    "TRAIN_FILE = os.path.join(BASE_PATH, \"train.json\")\n",
    "TABLES_PATH = os.path.join(BASE_PATH, \"WikiTables-WithLinks\", \"tables_tok\")\n",
    "\n",
    "# Function: Load specified number of training data\n",
    "def load_train_data(file_path, num_samples=None):\n",
    "    with open(file_path, 'r') as f:\n",
    "        train_data = json.load(f)\n",
    "    \n",
    "    if num_samples is not None and num_samples < len(train_data):\n",
    "        train_data = random.sample(train_data, num_samples)\n",
    "    \n",
    "    print(f\"Loaded {len(train_data)} training examples.\")\n",
    "    return train_data\n",
    "\n",
    "# Function: Load and process tables\n",
    "def load_table(table_id):\n",
    "    table_file = os.path.join(TABLES_PATH, f\"{table_id}.json\")\n",
    "    with open(table_file, 'r') as f:\n",
    "        table_data = json.load(f)\n",
    "    \n",
    "    headers = [h[0] for h in table_data['header']]\n",
    "    rows = []\n",
    "    for row in table_data['data']:\n",
    "        row_dict = {}\n",
    "        for i, cell in enumerate(row):\n",
    "            row_dict[headers[i]] = cell[0]\n",
    "        rows.append(row_dict)\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Prepare training data\n",
    "def prepare_training_data(train_data, num_negative_samples=3):\n",
    "    prepared_data = []\n",
    "    for item in tqdm(train_data, desc=\"Preparing training data\"):\n",
    "        question = item['question']\n",
    "        table_id = item['table_id']\n",
    "        labels = item['labels']\n",
    "        \n",
    "        # Load table\n",
    "        table = load_table(table_id)\n",
    "        \n",
    "        # Find positive samples (rows with label 1)\n",
    "        positive_indices = [i for i, label in enumerate(labels) if label == 1]\n",
    "        \n",
    "        for pos_idx in positive_indices:\n",
    "            positive_row = table.iloc[pos_idx].to_dict()\n",
    "            \n",
    "            # Select negative samples\n",
    "            negative_indices = [i for i, label in enumerate(labels) if label == 0]\n",
    "            negative_samples = random.sample(negative_indices, min(num_negative_samples, len(negative_indices)))\n",
    "            \n",
    "            for neg_idx in negative_samples:\n",
    "                negative_row = table.iloc[neg_idx].to_dict()\n",
    "                \n",
    "                prepared_data.append({\n",
    "                    'question': question,\n",
    "                    'positive_row': positive_row,\n",
    "                    'negative_row': negative_row,\n",
    "                    'table_id': table_id\n",
    "                })\n",
    "    \n",
    "    return prepared_data\n",
    "\n",
    "# User input for the amount of data to process\n",
    "num_samples = int(input(\"Enter the number of training samples to process (or 0 for all): \"))\n",
    "if num_samples <= 0:\n",
    "    num_samples = None\n",
    "\n",
    "# Load training data\n",
    "train_data = load_train_data(TRAIN_FILE, num_samples)\n",
    "\n",
    "# Prepare training data\n",
    "training_data = prepare_training_data(train_data)\n",
    "print(f\"Prepared {len(training_data)} training samples.\")\n",
    "\n",
    "# Show a sample\n",
    "sample = random.choice(training_data)\n",
    "print(\"Sample training data:\")\n",
    "print(f\"Question: {sample['question']}\")\n",
    "print(f\"Positive row: {sample['positive_row']}\")\n",
    "print(f\"Negative row: {sample['negative_row']}\")\n",
    "print(f\"Table ID: {sample['table_id']}\")\n",
    "\n",
    "# Save prepared training data\n",
    "output_file = os.path.join(BASE_PATH, f\"prepared_dpr_training_data_{len(train_data)}_samples.json\")\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(training_data, f)\n",
    "print(f\"Saved prepared training data to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bacdce8-e26b-4438-a3f6-0d71ddb9390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"HybridQA\"\n",
    "TEST_FILE = os.path.join(BASE_PATH, \"dev.json\")# or test\n",
    "TABLES_PATH = os.path.join(BASE_PATH, \"WikiTables-WithLinks\", \"tables_tok\")\n",
    "\n",
    "def load_test_data(file_path, num_samples=None):\n",
    "    with open(file_path, 'r') as f:\n",
    "        test_data = json.load(f)\n",
    "    \n",
    "    if num_samples is not None and num_samples < len(test_data):\n",
    "        test_data = random.sample(test_data, num_samples)\n",
    "    \n",
    "    print(f\"Loaded {len(test_data)} test examples.\")\n",
    "    return test_data\n",
    "\n",
    "def load_table(table_id):\n",
    "    table_file = os.path.join(TABLES_PATH, f\"{table_id}.json\")\n",
    "    with open(table_file, 'r') as f:\n",
    "        table_data = json.load(f)\n",
    "    \n",
    "    headers = [h[0] for h in table_data['header']]\n",
    "    rows = []\n",
    "    for row in table_data['data']:\n",
    "        row_dict = {}\n",
    "        for i, cell in enumerate(row):\n",
    "            row_dict[headers[i]] = cell[0]\n",
    "        rows.append(row_dict)\n",
    "    \n",
    "    return rows\n",
    "\n",
    "def prepare_test_data(test_data):\n",
    "    prepared_data = []\n",
    "    for item in tqdm(test_data, desc=\"Preparing test data\"):\n",
    "        question = item['question']\n",
    "        table_id = item['table_id']\n",
    "        labels = item['labels']\n",
    "        \n",
    "        table_rows = load_table(table_id)\n",
    "        \n",
    "        assert len(labels) == len(table_rows), f\"Mismatch in labels and rows for table {table_id}\"\n",
    "        \n",
    "        correct_row_index = labels.index(1) if 1 in labels else -1\n",
    "        \n",
    "        prepared_data.append({\n",
    "            'question': question,\n",
    "            'table_id': table_id,\n",
    "            'rows': table_rows,\n",
    "            'correct_row_index': correct_row_index\n",
    "        })\n",
    "    \n",
    "    return prepared_data\n",
    "\n",
    "num_samples = int(input(\"Enter the number of test samples to process (or 0 for all): \"))\n",
    "if num_samples <= 0:\n",
    "    num_samples = None\n",
    "\n",
    "test_data = load_test_data(TEST_FILE, num_samples)\n",
    "\n",
    "prepared_test_data = prepare_test_data(test_data)\n",
    "\n",
    "print(f\"Prepared {len(prepared_test_data)} test samples.\")\n",
    "\n",
    "sample = random.choice(prepared_test_data)\n",
    "print(\"\\nSample test data:\")\n",
    "print(f\"Question: {sample['question']}\")\n",
    "print(f\"Table ID: {sample['table_id']}\")\n",
    "print(f\"Number of rows: {len(sample['rows'])}\")\n",
    "print(f\"Correct row index: {sample['correct_row_index']}\")\n",
    "if sample['correct_row_index'] != -1:\n",
    "    print(f\"Correct row: {sample['rows'][sample['correct_row_index']]}\")\n",
    "\n",
    "output_file = os.path.join(BASE_PATH, f\"prepared_dpr_test_data_{len(test_data)}_samples.json\")\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(prepared_test_data, f)\n",
    "\n",
    "print(f\"\\nSaved prepared test data to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "553229a7-f8d9-47c4-b8ee-18b36931bfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prepared training data from Data/HybridQA/prepared_dpr_training_data_1_samples.json\n",
      "Loaded 21 prepared training samples.\n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|███████████████████████████████████| 1/1 [00:11<00:00, 11.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded data saved.\n",
      "Question embeddings shape: (21, 768)\n",
      "Positive embeddings shape: (21, 768)\n",
      "Negative embeddings shape: (21, 768)\n",
      "\n",
      "Sample embeddings:\n",
      "Question: [-0.5504775   0.31225264 -0.07330009 -0.06485221 -0.30499658]...\n",
      "Positive: [-0.6236328  -0.2962152  -0.18471776 -0.6544239  -0.531056  ]...\n",
      "Negative: [-0.5705106  -0.17978194 -0.13786103 -0.3468474  -0.24918976]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# testing DPR\n",
    "BASE_PATH = \"HybridQA\"\n",
    "PREPARED_DATA_FILE = os.path.join(BASE_PATH, \"prepared_dpr_training_data.json\")\n",
    "\n",
    "# DPR model definition\n",
    "class DPRModel(nn.Module):\n",
    "    def __init__(self, model_name='bert-base-uncased'):\n",
    "        super(DPRModel, self).__init__()\n",
    "        self.question_encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.passage_encoder = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def encode_question(self, input_ids, attention_mask):\n",
    "        return self.question_encoder(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "\n",
    "    def encode_passage(self, input_ids, attention_mask):\n",
    "        return self.passage_encoder(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "\n",
    "# Dataset class\n",
    "class DPRDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        question = item['question']\n",
    "        positive_row = ' '.join(str(v) for v in item['positive_row'].values())\n",
    "        negative_row = ' '.join(str(v) for v in item['negative_row'].values())\n",
    "\n",
    "        question_encoding = self.tokenizer(question, truncation=True, padding='max_length', \n",
    "                                           max_length=self.max_length, return_tensors='pt')\n",
    "        positive_encoding = self.tokenizer(positive_row, truncation=True, padding='max_length', \n",
    "                                           max_length=self.max_length, return_tensors='pt')\n",
    "        negative_encoding = self.tokenizer(negative_row, truncation=True, padding='max_length', \n",
    "                                           max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        return {\n",
    "            'question': {k: v.squeeze(0) for k, v in question_encoding.items()},\n",
    "            'positive': {k: v.squeeze(0) for k, v in positive_encoding.items()},\n",
    "            'negative': {k: v.squeeze(0) for k, v in negative_encoding.items()}\n",
    "        }\n",
    "\n",
    "# Encoding function\n",
    "def encode_data(model, dataset, device):\n",
    "    model.eval()\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    question_embeddings = []\n",
    "    positive_embeddings = []\n",
    "    negative_embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Encoding\"):\n",
    "            q_emb = model.encode_question(\n",
    "                batch['question']['input_ids'].to(device),\n",
    "                batch['question']['attention_mask'].to(device)\n",
    "            )\n",
    "            p_emb = model.encode_passage(\n",
    "                batch['positive']['input_ids'].to(device),\n",
    "                batch['positive']['attention_mask'].to(device)\n",
    "            )\n",
    "            n_emb = model.encode_passage(\n",
    "                batch['negative']['input_ids'].to(device),\n",
    "                batch['negative']['attention_mask'].to(device)\n",
    "            )\n",
    "            \n",
    "            question_embeddings.extend(q_emb.cpu().numpy())\n",
    "            positive_embeddings.extend(p_emb.cpu().numpy())\n",
    "            negative_embeddings.extend(n_emb.cpu().numpy())\n",
    "    \n",
    "    return np.array(question_embeddings), np.array(positive_embeddings), np.array(negative_embeddings)\n",
    "\n",
    "# Load saved training data\n",
    "print(f\"Loading prepared training data from {PREPARED_DATA_FILE}\")\n",
    "with open(PREPARED_DATA_FILE, \"r\") as f:\n",
    "    training_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(training_data)} prepared training samples.\")\n",
    "\n",
    "# Initialize device, tokenizer, and model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = DPRModel('bert-base-uncased').to(device)\n",
    "\n",
    "# Create dataset\n",
    "dataset = DPRDataset(training_data, tokenizer)\n",
    "\n",
    "# Encode data\n",
    "question_embeddings, positive_embeddings, negative_embeddings = encode_data(model, dataset, device)\n",
    "\n",
    "# Save encoded vectors\n",
    "np.save(os.path.join(BASE_PATH, \"question_embeddings.npy\"), question_embeddings)\n",
    "np.save(os.path.join(BASE_PATH, \"positive_embeddings.npy\"), positive_embeddings)\n",
    "np.save(os.path.join(BASE_PATH, \"negative_embeddings.npy\"), negative_embeddings)\n",
    "\n",
    "print(\"Encoded data saved.\")\n",
    "\n",
    "# Display shapes of encoded results\n",
    "print(f\"Question embeddings shape: {question_embeddings.shape}\")\n",
    "print(f\"Positive embeddings shape: {positive_embeddings.shape}\")\n",
    "print(f\"Negative embeddings shape: {negative_embeddings.shape}\")\n",
    "\n",
    "# Display a sample of encoded results\n",
    "print(\"\\nSample embeddings:\")\n",
    "print(f\"Question: {question_embeddings[0][:5]}...\")  # Only show first 5 elements\n",
    "print(f\"Positive: {positive_embeddings[0][:5]}...\")\n",
    "print(f\"Negative: {negative_embeddings[0][:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19a5105-6199-453f-aaf6-330ae3a9d0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
